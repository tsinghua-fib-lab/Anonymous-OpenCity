{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc80fea6-42ef-4546-bebb-157d18d68611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generativeAgent import GAGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97922151-0b92-40f7-97e3-bf7d5e118f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prototype storage\n",
    "import json\n",
    "\n",
    "def storage_agent_meta(agents, city, groups=None, groups_des=None):\n",
    "    stores = []\n",
    "    if groups == None:\n",
    "        for agent in agents:\n",
    "            agent_dict = {}\n",
    "            agent_dict['home'] = agent.Brain.Memory.Working.Reason['Homeplace']\n",
    "            agent_dict['work'] = agent.Brain.Memory.Working.Reason['Workplace']\n",
    "            agent_dict['genderDescription'] = agent.Brain.Memory.Working.Reason['genderDescription']\n",
    "            agent_dict['educationDescription'] = agent.Brain.Memory.Working.Reason['educationDescription']\n",
    "            agent_dict['consumptionDescription'] = agent.Brain.Memory.Working.Reason['consumptionDescription']\n",
    "            agent_dict['occupationDescription'] = agent.Brain.Memory.Working.Reason['occupationDescription']\n",
    "            stores.append(agent_dict)\n",
    "    else:\n",
    "        for group, agent_ids in groups.items():\n",
    "            for aid in agent_ids:\n",
    "                agent_dict = {}\n",
    "                agent_dict['group'] = group\n",
    "                agent_dict['home'] = agents[aid].Brain.Memory.Working.Reason['Homeplace']\n",
    "                agent_dict['work'] = agents[aid].Brain.Memory.Working.Reason['Workplace']\n",
    "                agent_dict['genderDescription'] = agents[aid].Brain.Memory.Working.Reason['genderDescription']\n",
    "                agent_dict['educationDescription'] = agents[aid].Brain.Memory.Working.Reason['educationDescription']\n",
    "                agent_dict['consumptionDescription'] = agents[aid].Brain.Memory.Working.Reason['consumptionDescription']\n",
    "                agent_dict['occupationDescription'] = agents[aid].Brain.Memory.Working.Reason['occupationDescription']\n",
    "                stores.append(agent_dict)\n",
    "    with open(f\"prototype/{city}/agents_meta.json\", 'w') as f:\n",
    "        json.dump(stores, f, indent=4)\n",
    "    if groups_des != None:\n",
    "        with open(f\"prototype/{city}/protos.json\", 'w') as f:\n",
    "            json.dump(groups_des, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7daf3fe-9a54-4db1-9bde-83b0d2726428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of target city\n",
    "ag = GAGroup(\"./config.yaml\", \"GA\", \"san_francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4884f-e638-485a-9823-4b2c33c7b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arg_1: number of agents\n",
    "arg_2: Day to simulate\n",
    "arg_3: (Optional) if you have already sampled profile for agents, you can use this to accelerate the initialization, other wise, it will sample profiles according to the city\n",
    "\"\"\"\n",
    "await ag.prepare_agents(1000, \"Sunday\", \"prototype/san_francisco/agents_meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a736e386-b09d-456c-b5ac-9512b4941cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * In-context Prototype Learning\n",
    "import json\n",
    "import asyncio\n",
    "import copy\n",
    "import random\n",
    "\n",
    "def get_profile_message(agent):\n",
    "    gender = agent.Brain.Memory.Working.Reason['genderDescription']\n",
    "    educationDescription = agent.Brain.Memory.Working.Reason['educationDescription']\n",
    "    consumptionDescription = agent.Brain.Memory.Working.Reason['consumptionDescription']\n",
    "    occupationDescription = agent.Brain.Memory.Working.Reason['occupationDescription']\n",
    "    personInfo = f\"{gender} {educationDescription} {occupationDescription} {consumptionDescription}\"\n",
    "    return personInfo\n",
    "\n",
    "def check_missing(agent_groups, number_of_agent):\n",
    "    ids = []\n",
    "    for _, value in agent_groups.items():\n",
    "        for aid in value:\n",
    "            if aid not in ids:\n",
    "                ids.append(aid)\n",
    "    ids = sorted(ids)\n",
    "    gap = 0\n",
    "    missing_ids = []\n",
    "    for i in range(len(ids)):\n",
    "        if ids[i]-gap != i:\n",
    "            missing_ids.append(i)\n",
    "            gap += 1\n",
    "    return missing_ids\n",
    "\n",
    "def check_repetation(agent_groups):\n",
    "    ids = []\n",
    "    for _, value in agent_groups.items():\n",
    "        ids += value\n",
    "    ids = sorted(ids)\n",
    "    repet = {}\n",
    "    total = 0\n",
    "    for i in range(len(ids)-1):\n",
    "        if ids[i] == ids[i+1]:\n",
    "            total += 1\n",
    "            if ids[i] in repet.keys():\n",
    "                repet[ids[i]] += 1\n",
    "            else:\n",
    "                repet[ids[i]] = 1\n",
    "    return repet\n",
    "\n",
    "def meta_group_sys(group_des):\n",
    "    messages = [{\n",
    "        'role': 'system',\n",
    "        'content': f\"\"\"\n",
    "## Function\n",
    "You are required to give a list of grades for the input entry to support the classification of the input entry.\n",
    "\n",
    "## Group Traits\n",
    "{group_des}\n",
    "\n",
    "## Requirement\n",
    "1. You should give the grade according to the relation between input entry and group trait.\n",
    "2. The grade is between [0, 1], bigger grade means closer relation.\n",
    "\n",
    "## Output Format\n",
    "Please output in JSON format with only a list in it.\n",
    "Example output: \n",
    "```json\n",
    "    [x, x, x, x, ...]\n",
    "```\n",
    "\"\"\"\n",
    "    }]\n",
    "    return messages\n",
    "\n",
    "async def group_from_proto(llm, agents, T, target_ids:list[int], group_des, log:bool=False) -> dict:\n",
    "    groups = {}\n",
    "    for id_ in target_ids:\n",
    "        messages_meta_sys = meta_group_sys(group_des)\n",
    "        group_metas = copy.deepcopy(list(group_des.keys()))\n",
    "        for key in group_metas:\n",
    "            if key not in groups.keys():\n",
    "                groups[key] = []\n",
    "        profile = get_profile_message(agents[id_])\n",
    "        if log:\n",
    "            print(profile)\n",
    "        messages = messages_meta_sys + [{'role': 'user', 'content': f\"\"\"\n",
    "## Input Entry:\n",
    "{profile}\n",
    "\"\"\"}]\n",
    "        while True:\n",
    "            try:\n",
    "                resp = await llm.atext_request(messages)\n",
    "                if log:\n",
    "                    print(resp)\n",
    "                resp = resp.strip('```json').strip('```')\n",
    "                score = json.loads(resp)\n",
    "                max_value = max(score)\n",
    "                max_index = score.index(max_value)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        if max_value >= T:\n",
    "            try:\n",
    "                name_ = group_metas[max_index]\n",
    "            except:\n",
    "                name_ = random.choice(group_metas)\n",
    "            groups[name_].append(id_)\n",
    "        else:\n",
    "            while True:\n",
    "                try:\n",
    "                    messages.append({\n",
    "                        'role': 'assistant', 'content': resp\n",
    "                    })\n",
    "                    messages.append({\n",
    "                        'role': 'user', 'content':\"\"\"\n",
    "        ## Function\n",
    "        According to your analysis, the possibility of this entry belonging to those above groups is not high, please give some insights.\n",
    "        \n",
    "        ## Output Format\n",
    "        JSON format of dictionay, which contains 2 keys ['group_name', 'trait']. group_name is the name of this new group. 'trait' is a summary of this group.\n",
    "        \n",
    "        Please give your answer:\n",
    "        \"\"\"\n",
    "                    })\n",
    "                    resp = await llm.atext_request(messages)\n",
    "                    if log:\n",
    "                        print(resp)\n",
    "                    resp = resp.strip('```json').strip('```')\n",
    "                    resp = json.loads(resp)\n",
    "                    new_group_name = resp['group_name']\n",
    "                    new_group_des = resp['trait']\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "            # update\n",
    "            groups[new_group_name] = [id_]\n",
    "            group_des[new_group_name] = new_group_des\n",
    "    return groups\n",
    "\n",
    "async def repair(llm, agents, groups, noa, T, group_des, log:bool=False) -> dict:\n",
    "    # delete redundant\n",
    "    repet = check_repetation(groups)\n",
    "    new_groups = copy.deepcopy(groups)\n",
    "    for aid, time in repet.items():\n",
    "        time_ = time\n",
    "        for key, agent_ids in groups.items():\n",
    "            agents_ = copy.deepcopy(agent_ids)\n",
    "            for i, num in enumerate(agent_ids):\n",
    "                if num == aid and time_ > 0:\n",
    "                    agents_.pop(i)\n",
    "                    time_ -= 1\n",
    "            if time_ <= 0:\n",
    "                new_groups[key] = agents_\n",
    "                break\n",
    "    \n",
    "    # check missing\n",
    "    miss = check_missing(new_groups, noa)\n",
    "\n",
    "    to_add = await group_from_proto(llm, agents, T, miss, group_des)\n",
    "    for key, _ in to_add.items():\n",
    "        if key in new_groups.keys():\n",
    "            new_groups[key] += copy.deepcopy(to_add[key])\n",
    "        else:\n",
    "            new_groups[key] = copy.deepcopy(to_add[key])\n",
    "    return new_groups, group_des\n",
    "    \n",
    "\n",
    "async def profile_meta_group(llm, agents, IG:int, MAN:int, T:float, batch_size:int=100, log:bool=False) -> dict:\n",
    "    \"\"\"\n",
    "    llm: a llm agent used for inference\n",
    "    agents: agents used for meta learning\n",
    "    IG: initial group\n",
    "    MAN: meta agent number that used for initial meta learning\n",
    "    T: threshold\n",
    "\n",
    "    path: \n",
    "    1. [initial agents] -> LLM -> [meta group](IG)\n",
    "    2. new agent -> LLM + [meta group] -> grade\n",
    "    3.1 grade > threashold: add to the group\n",
    "    3.2 grade < threashold: create a new group and add this group to [meta group]\n",
    "    4. back to 2 until all agents are grouped\n",
    "    \"\"\"\n",
    "    # * para check\n",
    "    print(\"---Check parameters...\")\n",
    "    if T <= 0 or T >=1:\n",
    "        print(\"Error: the threshold need to be set between (0, 1)\")\n",
    "        return None\n",
    "    # length of total agents\n",
    "    total_agent = len(agents)\n",
    "    if IG >= total_agent:\n",
    "        print(\"Error: the IG need to be set between [1, len(agents)]\")\n",
    "        return None\n",
    "    if MAN > total_agent:\n",
    "        print(\"Wrang: MAN greater than len(agents), set MAN to len(agents)\")\n",
    "        MAN = total_agent\n",
    "    print(\"---Start Meta Learning...\")\n",
    "    # * step 1\n",
    "    profile_list = \"\"\"\"\"\"\n",
    "    index = 0\n",
    "    for agent in agents[:MAN]:\n",
    "        profile = get_profile_message(agent)\n",
    "        profile_list += f\"{index}. {profile}\\n\"\n",
    "        index += 1\n",
    "    if log:\n",
    "        print(profile_list)\n",
    "    messages = [{\n",
    "        'role': 'user',\n",
    "        'content': f\"\"\"\n",
    "## Function\n",
    "According to your understanding, divide {MAN} enties groups. Each entry can be represents a personal information.\n",
    "\n",
    "## Requirement\n",
    "1. Totally {IG} groups.\n",
    "2. Grouping should be based on maximizing differences in daily behavior between groups.\n",
    "3. The grouping should be as general as possible to distinguish between different groups.\n",
    "4. Each group has a descriptive name.\n",
    "5. Each entry can only be assigned to the one and only group.\n",
    "\n",
    "## Output Format\n",
    "The output is required to be a dictionary in JSON format, containing 2 keys.\n",
    "The first key is 'group', which is a dictonary. It contains {IG} inner keys, representing the group name, and the inner value is a list which contains all ids(int) belonging to the group.\n",
    "The second key is 'trait', which  is a dictionry. It contains {IG} inner keys, representing the group name, and the inner value is a summary of the characteristics of the group.\n",
    "Do not include any explanatory information in the output.\n",
    "\n",
    "## Input\n",
    "{profile_list}\n",
    "\n",
    "Please give your answer:\n",
    "\"\"\"\n",
    "    }]\n",
    "    resp = await llm.atext_request(messages)\n",
    "    messages.append({'role': 'assistant', 'content': 'resp'})\n",
    "    if log:\n",
    "        print(resp)\n",
    "    resp = resp.strip('```json').strip('```')\n",
    "    intial_group = json.loads(resp)\n",
    "    groups = intial_group['group']\n",
    "    group_des = intial_group['trait']\n",
    "    sum_agent = 0\n",
    "    for key, value in groups.items():\n",
    "        sum_agent += len(value)\n",
    "\n",
    "    # * step 2: iteration\n",
    "    messages_meta_sys = meta_group_sys(group_des)\n",
    "    current_agent_index = index\n",
    "    batch_groups = []\n",
    "    group = []\n",
    "    for i in range(index, len(agents)):\n",
    "        group.append(i)\n",
    "        if len(group) == batch_size or i == len(agents)-1:\n",
    "            batch_groups.append(group)\n",
    "            group = []\n",
    "    tasks = [group_from_proto(llm, agents, T, batch_groups[i], group_des) for i in range(len(batch_groups))]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # gather\n",
    "    for group in results:\n",
    "        for key, _ in group.items():\n",
    "            if key in groups.keys():\n",
    "                groups[key] += copy.deepcopy(group[key])\n",
    "            else:\n",
    "                groups[key] = copy.deepcopy(group[key])\n",
    "                \n",
    "    grouped_agent = 0\n",
    "    for _, value in groups.items():\n",
    "        grouped_agent += len(value)\n",
    "    print(f\"---Finish Learning, total input agents【{len(agents)}】, grouped agent 【{grouped_agent}】 in 【{len(list(groups.keys()))}】 categories...\")\n",
    "    return groups, group_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbc5e7-7363-4299-9e9a-93a34072d799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Start in-context learning\n",
    "arg_1: LLM client\n",
    "arg_2: agents\n",
    "arg_3: number of groups to create from the inital group of agents\n",
    "arg_4: number of agents in initial group\n",
    "arg_5: threshold\n",
    "arg_6: acceleration option, we use async to accelerate the prototype learning process\n",
    "arg_7: weather output log messages\n",
    "\"\"\"\n",
    "groups, group_des = await profile_meta_group(ag.soul, ag.agents, 5, 20, 0.5, batch_size=100, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9020a96f-9c3b-45dd-801b-229ffa044aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"you can store your learning results for accelerating the simulation process, please refer to the prototype dirctory to check out the format\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
